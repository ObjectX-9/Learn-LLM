import { NextRequest } from 'next/server';
import { ChatOpenAI } from '@langchain/openai';
import {
  ChatPromptTemplate,
  SystemMessagePromptTemplate,
  HumanMessagePromptTemplate,
} from '@langchain/core/prompts';
import { StringOutputParser } from '@langchain/core/output_parsers';

export async function GET(request: NextRequest) {
  console.log('ğŸš€ SSE ChatGPTæµå¼è¯·æ±‚å¼€å§‹:', new Date().toISOString());

  const searchParams = request.nextUrl.searchParams;
  const userMessage = searchParams.get('message') || 'Hello, how are you?';
  const systemPrompt =
    searchParams.get('system') ||
    'You are a helpful AI assistant. Respond in a conversational and friendly manner.';
  const temperature = parseFloat(searchParams.get('temperature') || '0.7');
  const modelName = searchParams.get('model') || 'ge-2.5-flash-thinking';

  console.log('ğŸ“ ç”¨æˆ·æ¶ˆæ¯:', userMessage);
  console.log('ğŸ¤– æ¨¡å‹:', modelName);
  console.log('ğŸŒ¡ï¸ æ¸©åº¦:', temperature);

  const encoder = new TextEncoder();

  const readable = new ReadableStream({
    async start(controller) {
      console.log('ğŸ“¡ ChatGPTæµReadableStreamå¼€å§‹');

      try {
        // å‘é€å¼€å§‹çŠ¶æ€
        console.log('ğŸ“¤ å‘é€ChatGPTå¼€å§‹çŠ¶æ€');
        controller.enqueue(
          encoder.encode('event: status\ndata: å¼€å§‹AIå¯¹è¯\n\n')
        );

        controller.enqueue(encoder.encode('data: ğŸ¤– æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\n\n'));

        // åˆå§‹åŒ– ChatOpenAI
        const llm = new ChatOpenAI({
          openAIApiKey: process.env.OPEN_API_KEY,
          modelName: modelName,
          temperature: temperature,
          maxTokens: 2000,
          streaming: true,
          configuration: {
            baseURL: process.env.OPEN_API_BASE_URL,
          },
          verbose: true,
        });

        // åˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿
        const chatPrompt = ChatPromptTemplate.fromMessages([
          SystemMessagePromptTemplate.fromTemplate(systemPrompt),
          HumanMessagePromptTemplate.fromTemplate('{userMessage}'),
        ]);

        // åˆ›å»ºå¤„ç†é“¾
        const chain = chatPrompt.pipe(llm).pipe(new StringOutputParser());

        console.log('ğŸ”— å¼€å§‹æµå¼è°ƒç”¨LLM...');

        // å‘é€çŠ¶æ€æ›´æ–°
        controller.enqueue(
          encoder.encode('event: status\ndata: æ­£åœ¨ç”Ÿæˆå›ç­”\n\n')
        );

        // å¼€å§‹æµå¼è°ƒç”¨
        const stream = await chain.stream({
          userMessage: userMessage,
        });

        let totalTokens = 0;
        let responseText = '';
        let chunkCount = 0;

        // å‘é€å¼€å§‹å›ç­”çš„æ ‡è®°
        controller.enqueue(encoder.encode('data: \n\n'));

        console.log('ğŸ“¤ å¼€å§‹æ¥æ”¶LLMæµå¼å“åº”...');

        for await (const chunk of stream) {
          chunkCount++;
          totalTokens += chunk.length;
          responseText += chunk;

          console.log(`ğŸ“¤ å‘é€ç¬¬${chunkCount}ä¸ªchunk: "${chunk}"`);

          // å‘é€æµå¼å†…å®¹
          controller.enqueue(
            encoder.encode(`data: ${JSON.stringify({ content: chunk })}\n\n`)
          );

          // æ¯50ä¸ªchunkå‘é€ä¸€æ¬¡è¿›åº¦
          if (chunkCount % 50 === 0) {
            controller.enqueue(
              encoder.encode(
                `event: progress\ndata: å·²ç”Ÿæˆ ${chunkCount} ä¸ªtokenå—\n\n`
              )
            );
          }
        }

        console.log(
          `âœ… LLMå“åº”å®Œæˆï¼Œå…±${chunkCount}ä¸ªchunksï¼Œ${totalTokens}ä¸ªå­—ç¬¦`
        );

        // å‘é€å®ŒæˆçŠ¶æ€
        controller.enqueue(
          encoder.encode('event: status\ndata: å›ç­”ç”Ÿæˆå®Œæˆ\n\n')
        );

        // å‘é€ç»Ÿè®¡ä¿¡æ¯
        await new Promise((resolve) => setTimeout(resolve, 500));
        controller.enqueue(
          encoder.encode(
            `data: \n\nğŸ“Š å¯¹è¯ç»Ÿè®¡:\n- ç”Ÿæˆtokenå—: ${chunkCount}\n- å­—ç¬¦æ•°: ${totalTokens}\n- æ¨¡å‹: ${modelName}\n- æ¸©åº¦: ${temperature}\n\n`
          )
        );

        // å‘é€å®Œæˆäº‹ä»¶
        controller.enqueue(
          encoder.encode('event: complete\ndata: AIå¯¹è¯å®Œæˆ\n\n')
        );

        console.log('ğŸ”š ChatGPTæ¼”ç¤ºå®Œæˆï¼Œä¿æŒè¿æ¥ç­‰å¾…å‰ç«¯å…³é—­');
        // ä¸ä¸»åŠ¨å…³é—­è¿æ¥ï¼Œè®©å‰ç«¯æ§åˆ¶ä½•æ—¶å…³é—­
      } catch (error) {
        console.error('âŒ SSE ChatGPTå¤„ç†é”™è¯¯:', error);

        try {
          const errorMessage =
            error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
          controller.enqueue(
            encoder.encode(`data: âŒ ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: ${errorMessage}\n\n`)
          );

          controller.enqueue(
            encoder.encode('event: status\ndata: å‘ç”Ÿé”™è¯¯\n\n')
          );

          // å¦‚æœæ˜¯APIè°ƒç”¨ç›¸å…³é”™è¯¯ï¼Œæä¾›æ›´å‹å¥½çš„æç¤º
          if (
            errorMessage.includes('API') ||
            errorMessage.includes('401') ||
            errorMessage.includes('invalid')
          ) {
            controller.enqueue(
              encoder.encode('data: ğŸ’¡ æç¤º: è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®æ˜¯å¦æ­£ç¡®\n\n')
            );
          }
        } catch (closeError) {
          console.error('âŒ å‘é€é”™è¯¯ä¿¡æ¯æ—¶å‡ºé”™:', closeError);
        }
      }
    },

    cancel(reason) {
      console.log('âœ… ChatGPTå®¢æˆ·ç«¯æ­£å¸¸å…³é—­è¿æ¥:', reason?.name || reason);
      // è¿™æ˜¯æ­£å¸¸çš„è¿æ¥å…³é—­ï¼Œä¸éœ€è¦æŠ›å‡ºé”™è¯¯
    },
  });

  console.log('ğŸ“¡ è¿”å›ChatGPT Response');
  return new Response(readable, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET',
      'Access-Control-Allow-Headers': 'Cache-Control',
    },
  });
}
