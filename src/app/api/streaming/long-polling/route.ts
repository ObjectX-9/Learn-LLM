import { NextRequest } from 'next/server';
import { ChatOpenAI } from '@langchain/openai';
import {
  ChatPromptTemplate,
  SystemMessagePromptTemplate,
  HumanMessagePromptTemplate,
} from '@langchain/core/prompts';
import { StringOutputParser } from '@langchain/core/output_parsers';

interface LongPollingRequestPayload {
  message?: string;
  type?: 'text' | 'ai-chat' | 'data-stream' | 'log-stream' | 'notification';
  system?: string;
  temperature?: number;
  modelName?: string;
  timeout?: number;
  sequence?: number;
  clientId?: string;
}

// æ¨¡æ‹Ÿæ•°æ®å­˜å‚¨ - å®é™…é¡¹ç›®ä¸­åº”è¯¥ä½¿ç”¨å¤–éƒ¨å­˜å‚¨
const messageQueues = new Map<string, any[]>();
const clientSequences = new Map<string, number>();

// æ¸…ç†è¿‡æœŸçš„é˜Ÿåˆ—å’Œåºåˆ—
setInterval(() => {
  const now = Date.now();
  const entries = Array.from(messageQueues.entries());
  for (const [clientId, queue] of entries) {
    // æ¸…ç†è¶…è¿‡5åˆ†é’Ÿçš„æ—§æ•°æ®
    const filtered = queue.filter((msg: any) => now - msg.timestamp < 300000);
    if (filtered.length === 0) {
      messageQueues.delete(clientId);
      clientSequences.delete(clientId);
    } else {
      messageQueues.set(clientId, filtered);
    }
  }
}, 60000); // æ¯åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡

// GETæ–¹æ³• - Long Pollingè¯·æ±‚
export async function GET(request: NextRequest) {
  console.log('ğŸš€ Long Pollingè¯·æ±‚å¼€å§‹:', new Date().toISOString());

  const searchParams = request.nextUrl.searchParams;
  const clientId =
    searchParams.get('clientId') ||
    `client_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`;
  const type =
    (searchParams.get('type') as 'text' | 'data-stream' | 'notification') ||
    'text';
  const timeout = parseInt(searchParams.get('timeout') || '30000'); // é»˜è®¤30ç§’è¶…æ—¶
  const sequence = parseInt(searchParams.get('sequence') || '0');
  const message = searchParams.get('message') || 'Long Pollingæ¼”ç¤º';

  console.log('ğŸ“¡ Long Pollingå‚æ•°:', {
    clientId,
    type,
    timeout,
    sequence,
    message,
  });

  try {
    if (type === 'text') {
      return await handleTextPolling(clientId, message, timeout, sequence);
    } else if (type === 'data-stream') {
      return await handleDataPolling(clientId, timeout, sequence);
    } else if (type === 'notification') {
      return await handleNotificationPolling(clientId, timeout, sequence);
    }
  } catch (error) {
    console.error('âŒ Long Pollingå¤„ç†é”™è¯¯:', error);
    return Response.json(
      {
        type: 'error',
        message: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯',
        timestamp: Date.now(),
      },
      { status: 500 }
    );
  }
}

// POSTæ–¹æ³• - AIèŠå¤©Long Polling
export async function POST(request: NextRequest) {
  console.log('ğŸ¤– Long Polling AIèŠå¤©è¯·æ±‚å¼€å§‹:', new Date().toISOString());

  const body = (await request.json()) as LongPollingRequestPayload;
  const {
    message = 'è¯·ä»‹ç»ä¸€ä¸‹Long PollingæŠ€æœ¯',
    type = 'ai-chat',
    system = 'You are a helpful AI assistant. Please respond in Chinese.',
    temperature = 0.7,
    modelName = 'gpt-3.5-turbo',
    timeout = 30000,
    sequence = 0,
    clientId: providedClientId = null,
  } = body;

  const clientId =
    providedClientId ||
    `ai_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`;

  console.log('ğŸ¤– AI Long Pollingå‚æ•°:', {
    clientId,
    type,
    timeout,
    sequence,
    message,
  });

  try {
    if (type === 'ai-chat') {
      return await handleAIChatPolling(
        clientId,
        {
          message,
          system,
          temperature,
          modelName,
        },
        timeout,
        sequence
      );
    } else if (type === 'log-stream') {
      return await handleLogPolling(clientId, timeout, sequence);
    }
  } catch (error) {
    console.error('âŒ Long Polling AIå¤„ç†é”™è¯¯:', error);
    return Response.json(
      {
        type: 'error',
        message: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯',
        timestamp: Date.now(),
      },
      { status: 500 }
    );
  }
}

// æ–‡æœ¬Long Pollingå¤„ç†
async function handleTextPolling(
  clientId: string,
  message: string,
  timeout: number,
  sequence: number
) {
  console.log('ğŸ“¤ å¼€å§‹æ–‡æœ¬Long Polling');

  // åˆå§‹åŒ–å®¢æˆ·ç«¯é˜Ÿåˆ—
  if (!messageQueues.has(clientId)) {
    messageQueues.set(clientId, []);
    clientSequences.set(clientId, 0);

    // å¼‚æ­¥ç”Ÿæˆæ•°æ®
    generateTextData(clientId, message);
  }

  // ç­‰å¾…æ–°æ•°æ®æˆ–è¶…æ—¶
  const result = await waitForNewData(clientId, sequence, timeout);

  return Response.json(result, {
    headers: {
      'Cache-Control': 'no-cache',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// AIèŠå¤©Long Pollingå¤„ç†
async function handleAIChatPolling(
  clientId: string,
  options: {
    message: string;
    system: string;
    temperature: number;
    modelName: string;
  },
  timeout: number,
  sequence: number
) {
  console.log('ğŸ¤– å¼€å§‹AI Long Polling');

  // éªŒè¯APIå¯†é’¥
  if (!process.env.OPEN_API_KEY) {
    return Response.json({
      type: 'error',
      message: 'âŒ æœªé…ç½®OpenAI APIå¯†é’¥',
      timestamp: Date.now(),
      sequence: sequence + 1,
    });
  }

  // åˆå§‹åŒ–å®¢æˆ·ç«¯é˜Ÿåˆ—
  if (!messageQueues.has(clientId)) {
    messageQueues.set(clientId, []);
    clientSequences.set(clientId, 0);

    // å¼‚æ­¥ç”ŸæˆAIå›ç­”
    generateAIResponse(clientId, options);
  }

  // ç­‰å¾…æ–°æ•°æ®æˆ–è¶…æ—¶
  const result = await waitForNewData(clientId, sequence, timeout);

  return Response.json(result, {
    headers: {
      'Cache-Control': 'no-cache',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// æ•°æ®æµLong Pollingå¤„ç†
async function handleDataPolling(
  clientId: string,
  timeout: number,
  sequence: number
) {
  console.log('ğŸ“Š å¼€å§‹æ•°æ®Long Polling');

  // åˆå§‹åŒ–å®¢æˆ·ç«¯é˜Ÿåˆ—
  if (!messageQueues.has(clientId)) {
    messageQueues.set(clientId, []);
    clientSequences.set(clientId, 0);

    // å¼‚æ­¥ç”Ÿæˆæ•°æ®æµ
    generateDataStream(clientId);
  }

  // ç­‰å¾…æ–°æ•°æ®æˆ–è¶…æ—¶
  const result = await waitForNewData(clientId, sequence, timeout);

  return Response.json(result, {
    headers: {
      'Cache-Control': 'no-cache',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// é€šçŸ¥Long Pollingå¤„ç†
async function handleNotificationPolling(
  clientId: string,
  timeout: number,
  sequence: number
) {
  console.log('ğŸ”” å¼€å§‹é€šçŸ¥Long Polling');

  // åˆå§‹åŒ–å®¢æˆ·ç«¯é˜Ÿåˆ—
  if (!messageQueues.has(clientId)) {
    messageQueues.set(clientId, []);
    clientSequences.set(clientId, 0);

    // å¼‚æ­¥ç”Ÿæˆé€šçŸ¥
    generateNotifications(clientId);
  }

  // ç­‰å¾…æ–°æ•°æ®æˆ–è¶…æ—¶
  const result = await waitForNewData(clientId, sequence, timeout);

  return Response.json(result, {
    headers: {
      'Cache-Control': 'no-cache',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// æ—¥å¿—æµLong Pollingå¤„ç†
async function handleLogPolling(
  clientId: string,
  timeout: number,
  sequence: number
) {
  console.log('ğŸ“ å¼€å§‹æ—¥å¿—Long Polling');

  // åˆå§‹åŒ–å®¢æˆ·ç«¯é˜Ÿåˆ—
  if (!messageQueues.has(clientId)) {
    messageQueues.set(clientId, []);
    clientSequences.set(clientId, 0);

    // å¼‚æ­¥ç”Ÿæˆæ—¥å¿—
    generateLogStream(clientId);
  }

  // ç­‰å¾…æ–°æ•°æ®æˆ–è¶…æ—¶
  const result = await waitForNewData(clientId, sequence, timeout);

  return Response.json(result, {
    headers: {
      'Cache-Control': 'no-cache',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// ç­‰å¾…æ–°æ•°æ®æˆ–è¶…æ—¶
async function waitForNewData(
  clientId: string,
  requestSequence: number,
  timeout: number
) {
  const startTime = Date.now();
  const maxWaitTime = Math.min(timeout, 60000); // æœ€å¤§ç­‰å¾…60ç§’

  while (Date.now() - startTime < maxWaitTime) {
    const queue = messageQueues.get(clientId) || [];
    const currentSequence = clientSequences.get(clientId) || 0;

    // æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®
    if (currentSequence > requestSequence) {
      const newMessages = queue.filter((msg) => msg.sequence > requestSequence);

      // æ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆæ ‡è®°
      const hasCompleteMessage = newMessages.some(
        (msg) =>
          msg.type &&
          (msg.type === 'complete' ||
            msg.type === 'chat-complete' ||
            msg.type === 'data-complete' ||
            msg.type === 'log-complete' ||
            msg.type === 'notification-complete' ||
            msg.type === 'error' ||
            msg.type === 'chat-error')
      );

      return {
        type: 'data',
        messages: newMessages,
        sequence: currentSequence,
        hasMore: !hasCompleteMessage, // å¦‚æœæœ‰å®Œæˆæ¶ˆæ¯ï¼Œåˆ™ä¸å†æœ‰æ›´å¤šæ•°æ®
        clientId,
        timestamp: Date.now(),
      };
    }

    // ç­‰å¾…50mså†æ£€æŸ¥
    await new Promise((resolve) => setTimeout(resolve, 50));
  }

  // è¶…æ—¶è¿”å›
  return {
    type: 'timeout',
    message: 'Long Pollingè¶…æ—¶ï¼Œè¯·é‡æ–°è¯·æ±‚',
    sequence: requestSequence,
    hasMore: true,
    clientId,
    timestamp: Date.now(),
  };
}

// æ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ—
function addMessageToQueue(clientId: string, message: any) {
  const queue = messageQueues.get(clientId) || [];
  const currentSequence = (clientSequences.get(clientId) || 0) + 1;

  const messageWithSequence = {
    ...message,
    sequence: currentSequence,
    timestamp: Date.now(),
  };

  queue.push(messageWithSequence);
  messageQueues.set(clientId, queue);
  clientSequences.set(clientId, currentSequence);

  console.log(`ğŸ“¤ æ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ— ${clientId}:`, messageWithSequence.type);
}

// ç”Ÿæˆæ–‡æœ¬æ•°æ®
async function generateTextData(clientId: string, message: string) {
  console.log('ğŸ“ å¼€å§‹ç”Ÿæˆæ–‡æœ¬æ•°æ®');

  addMessageToQueue(clientId, {
    type: 'start',
    message: 'ğŸ‰ Long Pollingè¿æ¥å»ºç«‹æˆåŠŸï¼',
  });

  const segments = [
    `æ¬¢è¿ä½¿ç”¨ Long Polling æŠ€æœ¯ï¼`,
    `æ‚¨çš„æ¶ˆæ¯: ${message}`,
    'Long Pollingæ˜¯ä¸€ç§å®æ—¶é€šä¿¡æŠ€æœ¯',
    'å®¢æˆ·ç«¯å‘èµ·è¯·æ±‚åï¼ŒæœåŠ¡å™¨ä¼šä¿æŒè¿æ¥',
    'ç›´åˆ°æœ‰æ–°æ•°æ®è¿”å›æˆ–è€…è¶…æ—¶',
    'è¿™ç§æ–¹å¼æ¨¡æ‹Ÿäº†æœåŠ¡å™¨æ¨é€çš„æ•ˆæœ',
    'ç›¸æ¯”ä¼ ç»Ÿè½®è¯¢ï¼Œå‡å°‘äº†ä¸å¿…è¦çš„è¯·æ±‚',
    'ä½†ä»ç„¶åŸºäºHTTPè¯·æ±‚-å“åº”æ¨¡å¼',
    'é€‚åˆæ¶ˆæ¯é¢‘ç‡ä¸å¤ªé«˜çš„åœºæ™¯',
    'æ¼”ç¤ºå³å°†ç»“æŸ...',
  ];

  for (let i = 0; i < segments.length; i++) {
    await new Promise((resolve) => setTimeout(resolve, 1000));

    addMessageToQueue(clientId, {
      type: 'data',
      content: segments[i],
      index: i + 1,
      total: segments.length,
      progress: Math.round(((i + 1) / segments.length) * 100),
    });
  }

  addMessageToQueue(clientId, {
    type: 'complete',
    message: 'âœ… Long Pollingæ¼”ç¤ºå®Œæˆ',
    totalSegments: segments.length,
  });
}

// ç”ŸæˆAIå›ç­”
async function generateAIResponse(
  clientId: string,
  options: {
    message: string;
    system: string;
    temperature: number;
    modelName: string;
  }
) {
  console.log('ğŸ¤– å¼€å§‹ç”ŸæˆAIå›ç­”');

  addMessageToQueue(clientId, {
    type: 'chat-start',
    message: 'ğŸ¤– AIæ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...',
    model: options.modelName,
  });

  try {
    // åˆå§‹åŒ–AIæ¨¡å‹ï¼ˆéæµå¼ï¼‰
    const llm = new ChatOpenAI({
      openAIApiKey: process.env.OPEN_API_KEY,
      modelName: options.modelName,
      temperature: options.temperature,
      maxTokens: 2000,
      configuration: {
        baseURL: process.env.OPEN_API_BASE_URL,
      },
    });

    // åˆ›å»ºæç¤ºæ¨¡æ¿
    const chatPrompt = ChatPromptTemplate.fromMessages([
      SystemMessagePromptTemplate.fromTemplate(options.system),
      HumanMessagePromptTemplate.fromTemplate('{userMessage}'),
    ]);

    // åˆ›å»ºå¤„ç†é“¾
    const chain = chatPrompt.pipe(llm).pipe(new StringOutputParser());

    // éæµå¼è°ƒç”¨ï¼ˆLong Pollingé€šå¸¸è¿”å›å®Œæ•´å“åº”ï¼‰
    const response = await chain.invoke({
      userMessage: options.message,
    });

    // å°†å›ç­”åˆ†æ®µæ¨é€ï¼ˆæ¨¡æ‹Ÿé€å¥è¿”å›ï¼‰
    const sentences = response.split(/[ã€‚ï¼ï¼Ÿ.!?]\s*/);
    let accumulatedContent = '';

    for (let i = 0; i < sentences.length; i++) {
      if (sentences[i].trim()) {
        accumulatedContent += sentences[i] + 'ã€‚';

        await new Promise((resolve) => setTimeout(resolve, 800));

        addMessageToQueue(clientId, {
          type: 'chat-stream',
          content: sentences[i] + 'ã€‚',
          totalContent: accumulatedContent,
          sentenceIndex: i + 1,
          totalSentences: sentences.length,
        });
      }
    }

    addMessageToQueue(clientId, {
      type: 'chat-complete',
      message: 'âœ… AIå›ç­”ç”Ÿæˆå®Œæˆ',
      totalContent: accumulatedContent,
      model: options.modelName,
    });
  } catch (error) {
    console.error('âŒ AIå¤„ç†é”™è¯¯:', error);
    addMessageToQueue(clientId, {
      type: 'chat-error',
      message: `âŒ AIå¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
    });
  }
}

// ç”Ÿæˆæ•°æ®æµ
async function generateDataStream(clientId: string) {
  console.log('ğŸ“Š å¼€å§‹ç”Ÿæˆæ•°æ®æµ');

  addMessageToQueue(clientId, {
    type: 'data-start',
    message: 'ğŸ“Š å¼€å§‹å®æ—¶æ•°æ®æµä¼ è¾“',
  });

  // ç”Ÿæˆ20ä¸ªæ•°æ®ç‚¹
  for (let i = 0; i < 20; i++) {
    await new Promise((resolve) => setTimeout(resolve, 500));

    const dataPoint = {
      type: 'data-point',
      index: i + 1,
      value: Math.sin(i * 0.3) * 50 + 50 + Math.random() * 10,
      cpu: Math.random() * 100,
      memory: Math.random() * 100,
      network: Math.random() * 1000,
      temperature: Math.random() * 40 + 20,
    };

    addMessageToQueue(clientId, dataPoint);
  }

  addMessageToQueue(clientId, {
    type: 'data-complete',
    message: 'âœ… æ•°æ®æµä¼ è¾“å®Œæˆ',
    totalPoints: 20,
  });
}

// ç”Ÿæˆé€šçŸ¥
async function generateNotifications(clientId: string) {
  console.log('ğŸ”” å¼€å§‹ç”Ÿæˆé€šçŸ¥');

  const notifications = [
    {
      type: 'info',
      title: 'ç³»ç»Ÿé€šçŸ¥',
      message: 'æ¬¢è¿ä½¿ç”¨ Long Polling é€šçŸ¥ç³»ç»Ÿ',
    },
    { type: 'success', title: 'æ“ä½œæˆåŠŸ', message: 'æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“' },
    {
      type: 'warning',
      title: 'æ³¨æ„',
      message: 'ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡è¾ƒé«˜ï¼Œè¯·æ³¨æ„ç›‘æ§',
    },
    { type: 'error', title: 'é”™è¯¯', message: 'ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œæ­£åœ¨è‡ªåŠ¨é‡è¯•' },
    { type: 'info', title: 'æ›´æ–°', message: 'å‘ç°æ–°ç‰ˆæœ¬ v2.1.0ï¼Œå»ºè®®ç«‹å³æ›´æ–°' },
  ];

  addMessageToQueue(clientId, {
    type: 'notification-start',
    message: 'ğŸ”” å¼€å§‹é€šçŸ¥æ¨é€',
  });

  for (let i = 0; i < notifications.length; i++) {
    await new Promise((resolve) => setTimeout(resolve, 2000));

    addMessageToQueue(clientId, {
      type: 'notification',
      title: notifications[i].title,
      message: notifications[i].message,
      level: notifications[i].type, // ä¿å­˜é€šçŸ¥çº§åˆ«
      id: Date.now() + i,
      index: i + 1,
    });
  }

  addMessageToQueue(clientId, {
    type: 'notification-complete',
    message: 'âœ… é€šçŸ¥æ¨é€å®Œæˆ',
    totalNotifications: notifications.length,
  });
}

// ç”Ÿæˆæ—¥å¿—æµ
async function generateLogStream(clientId: string) {
  console.log('ğŸ“ å¼€å§‹ç”Ÿæˆæ—¥å¿—æµ');

  const logs = [
    { level: 'info', message: 'Long Polling ç³»ç»Ÿå¯åŠ¨' },
    { level: 'debug', message: 'åŠ è½½é…ç½®æ–‡ä»¶...' },
    { level: 'info', message: 'æ•°æ®åº“è¿æ¥å·²å»ºç«‹' },
    { level: 'warn', message: 'æ£€æµ‹åˆ°é«˜CPUä½¿ç”¨ç‡: 85%' },
    { level: 'info', message: 'å¤„ç†ç”¨æˆ·è¯·æ±‚...' },
    { level: 'debug', message: 'æ‰§è¡Œæ•°æ®æŸ¥è¯¢æ“ä½œ' },
    { level: 'error', message: 'ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...' },
    { level: 'info', message: 'é‡è¿æˆåŠŸ' },
    { level: 'debug', message: 'æ•°æ®å¤„ç†å®Œæˆ' },
    { level: 'info', message: 'å“åº”å·²å‘é€' },
  ];

  addMessageToQueue(clientId, {
    type: 'log-start',
    message: 'ğŸ“ å¼€å§‹æ—¥å¿—æµä¼ è¾“',
  });

  for (let i = 0; i < logs.length; i++) {
    await new Promise((resolve) => setTimeout(resolve, 700));

    addMessageToQueue(clientId, {
      type: 'log-entry',
      ...logs[i],
      id: `log_${Date.now()}_${i}`,
      index: i + 1,
    });
  }

  addMessageToQueue(clientId, {
    type: 'log-complete',
    message: 'âœ… æ—¥å¿—æµä¼ è¾“å®Œæˆ',
    totalLogs: logs.length,
  });
}
