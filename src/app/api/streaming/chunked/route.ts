import { NextRequest } from 'next/server';
import { ChatOpenAI } from '@langchain/openai';
import {
  ChatPromptTemplate,
  SystemMessagePromptTemplate,
  HumanMessagePromptTemplate,
} from '@langchain/core/prompts';
import { StringOutputParser } from '@langchain/core/output_parsers';

interface ChunkedRequestPayload {
  message?: string;
  type?: 'text' | 'ai-chat' | 'data-stream' | 'log-stream';
  system?: string;
  temperature?: number;
  modelName?: string;
  duration?: number;
  interval?: number;
}

// GETæ–¹æ³• - ç®€å•æ–‡æœ¬æµå¼è¾“å‡º
export async function GET(request: NextRequest) {
  console.log('ğŸš€ Chunked Transferè¯·æ±‚å¼€å§‹:', new Date().toISOString());

  const searchParams = request.nextUrl.searchParams;
  const message = searchParams.get('message') || 'Chunked Transferæ¼”ç¤ºæ–‡æœ¬';
  const type = (searchParams.get('type') as 'text' | 'data-stream') || 'text';

  const encoder = new TextEncoder();

  const readable = new ReadableStream({
    async start(controller) {
      console.log('ğŸ“¡ Chunked ReadableStreamå¼€å§‹');

      try {
        if (type === 'text') {
          await handleTextStream(controller, encoder, message);
        } else if (type === 'data-stream') {
          await handleDataStream(controller, encoder);
        }
      } catch (error) {
        console.error('âŒ Chunkedå¤„ç†é”™è¯¯:', error);
        const errorData = JSON.stringify({
          type: 'error',
          message: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯',
          timestamp: Date.now(),
        });
        controller.enqueue(
          encoder.encode(`${errorData.length.toString(16)}\r\n${errorData}\r\n`)
        );
        controller.enqueue(encoder.encode('0\r\n\r\n')); // ç»“æŸæ ‡è®°
        controller.close();
      }
    },

    cancel(reason) {
      console.log('âœ… Chunkedå®¢æˆ·ç«¯å…³é—­è¿æ¥:', reason?.name || reason);
    },
  });

  return new Response(readable, {
    headers: {
      'Content-Type': 'application/json',
      'Transfer-Encoding': 'chunked',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// POSTæ–¹æ³• - AIèŠå¤©æµå¼è¾“å‡º
export async function POST(request: NextRequest) {
  console.log('ğŸ¤– Chunked AIèŠå¤©è¯·æ±‚å¼€å§‹:', new Date().toISOString());

  const body = (await request.json()) as ChunkedRequestPayload;
  const {
    message = 'ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹Chunked Transferç¼–ç ',
    type = 'ai-chat',
    system = 'You are a helpful AI assistant. Please respond in Chinese.',
    temperature = 0.7,
    modelName = 'gpt-3.5-turbo',
  } = body;

  const encoder = new TextEncoder();

  const readable = new ReadableStream({
    async start(controller) {
      try {
        if (type === 'ai-chat') {
          await handleAIChatStream(controller, encoder, {
            message,
            system,
            temperature,
            modelName,
          });
        } else if (type === 'log-stream') {
          await handleLogStream(controller, encoder);
        }
      } catch (error) {
        console.error('âŒ Chunked AIå¤„ç†é”™è¯¯:', error);
        const errorData = JSON.stringify({
          type: 'error',
          message: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯',
          timestamp: Date.now(),
        });
        controller.enqueue(
          encoder.encode(`${errorData.length.toString(16)}\r\n${errorData}\r\n`)
        );
        controller.enqueue(encoder.encode('0\r\n\r\n'));
        controller.close();
      }
    },

    cancel(reason) {
      console.log('âœ… Chunked AIå®¢æˆ·ç«¯å…³é—­è¿æ¥:', reason?.name || reason);
    },
  });

  return new Response(readable, {
    headers: {
      'Content-Type': 'application/json',
      'Transfer-Encoding': 'chunked',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// å‘é€Chunkedæ•°æ®çš„è¾…åŠ©å‡½æ•°
function sendChunk(
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder,
  data: any
) {
  const jsonData = JSON.stringify(data);
  const chunkSize = jsonData.length.toString(16); // åå…­è¿›åˆ¶é•¿åº¦
  controller.enqueue(encoder.encode(`${chunkSize}\r\n${jsonData}\r\n`));
}

// æ–‡æœ¬æµå¤„ç†
async function handleTextStream(
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder,
  message: string
) {
  console.log('ğŸ“¤ å¼€å§‹Chunkedæ–‡æœ¬æµ');

  // å‘é€å¼€å§‹æ¶ˆæ¯
  sendChunk(controller, encoder, {
    type: 'start',
    message: 'ğŸ‰ Chunked Transferè¿æ¥å»ºç«‹æˆåŠŸï¼',
    timestamp: Date.now(),
  });

  // åˆ†æ®µå‘é€æ¶ˆæ¯
  const segments = [
    'æ¬¢è¿ä½¿ç”¨ Chunked Transfer æµå¼è¾“å‡ºï¼',
    `æ‚¨çš„æ¶ˆæ¯: ${message}`,
    'è¿™æ˜¯ç¬¬ä¸€æ®µæ•°æ®...',
    'è¿™æ˜¯ç¬¬äºŒæ®µæ•°æ®...',
    'è¿™æ˜¯ç¬¬ä¸‰æ®µæ•°æ®...',
    'Chunked Transferç¼–ç å…è®¸æœåŠ¡å™¨åœ¨ä¸çŸ¥é“æ€»å†…å®¹é•¿åº¦çš„æƒ…å†µä¸‹å‘é€æ•°æ®',
    'æ¯ä¸ªæ•°æ®å—éƒ½æœ‰è‡ªå·±çš„é•¿åº¦æ ‡è¯†',
    'è¿™æ ·å¯ä»¥å®ç°çœŸæ­£çš„æµå¼ä¼ è¾“',
    'éå¸¸é€‚åˆå®æ—¶æ•°æ®æ¨é€åœºæ™¯',
    'æ¼”ç¤ºå³å°†ç»“æŸ...',
  ];

  for (let i = 0; i < segments.length; i++) {
    console.log(`ğŸ“¤ å‘é€Chunkedç‰‡æ®µ ${i + 1}/${segments.length}`);

    sendChunk(controller, encoder, {
      type: 'data',
      content: segments[i],
      index: i + 1,
      total: segments.length,
      progress: Math.round(((i + 1) / segments.length) * 100),
      timestamp: Date.now(),
    });

    // å»¶è¿Ÿæ¨¡æ‹Ÿæµå¼æ•ˆæœ
    await new Promise((resolve) => setTimeout(resolve, 800));
  }

  // å‘é€å®Œæˆæ¶ˆæ¯
  sendChunk(controller, encoder, {
    type: 'complete',
    message: 'âœ… Chunked Transferæ¼”ç¤ºå®Œæˆ',
    totalSegments: segments.length,
    timestamp: Date.now(),
  });

  // å‘é€ç»“æŸæ ‡è®°
  controller.enqueue(encoder.encode('0\r\n\r\n'));
  controller.close();
}

// AIèŠå¤©æµå¤„ç†
async function handleAIChatStream(
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder,
  options: {
    message: string;
    system: string;
    temperature: number;
    modelName: string;
  }
) {
  const { message, system, temperature, modelName } = options;

  console.log('ğŸ¤– å¼€å§‹Chunked AIèŠå¤©æµ');

  // éªŒè¯APIå¯†é’¥
  if (!process.env.OPEN_API_KEY) {
    sendChunk(controller, encoder, {
      type: 'error',
      message: 'âŒ æœªé…ç½®OpenAI APIå¯†é’¥',
      timestamp: Date.now(),
    });
    controller.enqueue(encoder.encode('0\r\n\r\n'));
    controller.close();
    return;
  }

  // å‘é€å¼€å§‹æ¶ˆæ¯
  sendChunk(controller, encoder, {
    type: 'chat-start',
    message: 'ğŸ¤– AIæ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...',
    model: modelName,
    timestamp: Date.now(),
  });

  try {
    // åˆå§‹åŒ–AIæ¨¡å‹
    const llm = new ChatOpenAI({
      openAIApiKey: process.env.OPEN_API_KEY,
      modelName: modelName,
      temperature: temperature,
      maxTokens: 2000,
      streaming: true,
      configuration: {
        baseURL: process.env.OPEN_API_BASE_URL,
      },
    });

    // åˆ›å»ºæç¤ºæ¨¡æ¿
    const chatPrompt = ChatPromptTemplate.fromMessages([
      SystemMessagePromptTemplate.fromTemplate(system),
      HumanMessagePromptTemplate.fromTemplate('{userMessage}'),
    ]);

    // åˆ›å»ºå¤„ç†é“¾
    const chain = chatPrompt.pipe(llm).pipe(new StringOutputParser());

    // æµå¼è°ƒç”¨
    const stream = await chain.stream({
      userMessage: message,
    });

    let chunkCount = 0;
    let totalContent = '';

    for await (const chunk of stream) {
      chunkCount++;
      totalContent += chunk;

      // å‘é€æµå¼å†…å®¹
      sendChunk(controller, encoder, {
        type: 'chat-stream',
        content: chunk,
        chunkCount,
        totalLength: totalContent.length,
        timestamp: Date.now(),
      });
    }

    // å‘é€å®Œæˆæ¶ˆæ¯
    sendChunk(controller, encoder, {
      type: 'chat-complete',
      message: 'âœ… AIå›ç­”ç”Ÿæˆå®Œæˆ',
      totalChunks: chunkCount,
      totalContent: totalContent,
      model: modelName,
      timestamp: Date.now(),
    });
  } catch (error) {
    console.error('âŒ AIå¤„ç†é”™è¯¯:', error);
    sendChunk(controller, encoder, {
      type: 'chat-error',
      message: `âŒ AIå¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
      timestamp: Date.now(),
    });
  }

  // å‘é€ç»“æŸæ ‡è®°
  controller.enqueue(encoder.encode('0\r\n\r\n'));
  controller.close();
}

// æ•°æ®æµå¤„ç†
async function handleDataStream(
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder
) {
  console.log('ğŸ“Š å¼€å§‹Chunkedæ•°æ®æµ');

  sendChunk(controller, encoder, {
    type: 'data-start',
    message: 'ğŸ“Š å¼€å§‹å®æ—¶æ•°æ®æµä¼ è¾“',
    timestamp: Date.now(),
  });

  // ç”Ÿæˆ20ä¸ªæ•°æ®ç‚¹
  for (let i = 0; i < 20; i++) {
    const dataPoint = {
      type: 'data-point',
      timestamp: Date.now(),
      index: i + 1,
      value: Math.sin(i * 0.3) * 50 + 50 + Math.random() * 10,
      cpu: Math.random() * 100,
      memory: Math.random() * 100,
      network: Math.random() * 1000,
      temperature: Math.random() * 40 + 20,
    };

    sendChunk(controller, encoder, dataPoint);
    await new Promise((resolve) => setTimeout(resolve, 300));
  }

  sendChunk(controller, encoder, {
    type: 'data-complete',
    message: 'âœ… æ•°æ®æµä¼ è¾“å®Œæˆ',
    totalPoints: 20,
    timestamp: Date.now(),
  });

  controller.enqueue(encoder.encode('0\r\n\r\n'));
  controller.close();
}

// æ—¥å¿—æµå¤„ç†
async function handleLogStream(
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder
) {
  console.log('ğŸ“ å¼€å§‹Chunkedæ—¥å¿—æµ');

  const logs = [
    { level: 'info', message: 'Chunked Transfer ç³»ç»Ÿå¯åŠ¨' },
    { level: 'debug', message: 'åŠ è½½é…ç½®æ–‡ä»¶...' },
    { level: 'info', message: 'æ•°æ®åº“è¿æ¥å·²å»ºç«‹' },
    { level: 'warn', message: 'æ£€æµ‹åˆ°é«˜CPUä½¿ç”¨ç‡: 85%' },
    { level: 'info', message: 'å¤„ç†ç”¨æˆ·è¯·æ±‚...' },
    { level: 'debug', message: 'æ‰§è¡Œæ•°æ®æŸ¥è¯¢æ“ä½œ' },
    { level: 'error', message: 'ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...' },
    { level: 'info', message: 'é‡è¿æˆåŠŸ' },
    { level: 'debug', message: 'æ•°æ®å¤„ç†å®Œæˆ' },
    { level: 'info', message: 'å“åº”å·²å‘é€' },
  ];

  sendChunk(controller, encoder, {
    type: 'log-start',
    message: 'ğŸ“ å¼€å§‹æ—¥å¿—æµä¼ è¾“',
    timestamp: Date.now(),
  });

  for (let i = 0; i < logs.length; i++) {
    const logEntry = {
      type: 'log-entry',
      ...logs[i],
      timestamp: Date.now(),
      id: `log_${Date.now()}_${i}`,
      index: i + 1,
    };

    sendChunk(controller, encoder, logEntry);
    await new Promise((resolve) => setTimeout(resolve, 500));
  }

  sendChunk(controller, encoder, {
    type: 'log-complete',
    message: 'âœ… æ—¥å¿—æµä¼ è¾“å®Œæˆ',
    totalLogs: logs.length,
    timestamp: Date.now(),
  });

  controller.enqueue(encoder.encode('0\r\n\r\n'));
  controller.close();
}
